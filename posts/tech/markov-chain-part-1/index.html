<!DOCTYPE html>
<html lang="en" class="js csstransforms3d">
  <head>
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      <meta property="og:title" content="Markov chain: What is a Markov chain?">
      <title>Thuyen&#39;s corner</title>
      <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.8/styles/default.min.css">
      <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.6.3/css/all.css" integrity="sha384-UHRtZLI+pbxtHCWp1t77Bi1L4ZtiqrqD80Kn4Z8NTSRyMA2Fd33n5dQ8lWUE00s/" crossorigin="anonymous">
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.8/highlight.min.js"></script>
      
      <link rel="stylesheet" href="https://trinhngocthuyen.github.io/sass/main.7c9da60ff2d0ede050060cc37446d405a6ebc67b1b72688fd9329eba535d7f72.css">

      
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-69597239-3', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>

  </head>
  <body class="" data-url="/posts/tech/markov-chain-part-1/">
    <nav role="navigation">
  <header role="banner">
    <h1 id="logo">
      <a href="/">Thuyen&#39;s corner</a>
    </h1>
  </header>
  <div id="menu-toggle" class="menu-toggle">
    <span class='open'><svg class='icon' viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
  
  <line x1="3" y1="12" x2="21" y2="12" />
  <line x1="3" y1="6" x2="21" y2="6" />
  <line x1="3" y1="18" x2="21" y2="18" />
  
</svg>
</span>
    <span class='close'><svg class='icon' viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
  
  <line x1="18" y1="6" x2="6" y2="18" />
  <line x1="6" y1="6" x2="18" y2="18" />
  
</svg>
</span>
  </div>
  <ul>
    
    <li><a href="/posts/tech">Tech</a></li>
    
    <li><a href="/posts/misc">Misc (Táº¡p bÃºt)</a></li>
    
    <li><a href="/about">About</a></li>
    
  </ul>
</nav>

<script src="/scripts/menu.js"></script>
    <main role="main">
<article class="page">
  <header>
  
  <h1>Markov chain: What is a Markov chain?</h1>
  
  
  <div class="metadata">
  <span>2018, Jan 31</span>
</div>
  
</header>
  <p>Markov chain is a very important piece of probability and statistics. One application we could name is Markov Decision Process (MDP) used for decision making. Another one is Markov chain Monte Carlo (MCMC), a popular sampling method in statistics. You may also know Google PageRank algorithm, which is part of the ground of Google indexing technology. The algorithm is implemented on top of this concept.</p>
<p>This is a part of a series about Markov chain&hellip; In this post, we will look into some of its fundamental concepts.</p>
<p><em>Disclaimer: I am no expert in probability and statistics. These I am about to write are based on my understanding when reading the book <a href="https://www.amazon.com/Introduction-Probability-Chapman-Statistical-Science/dp/1466575573">&ldquo;Introduction to Probability&rdquo;</a> by Joseph K. Blitzstein and Jessica Hwang. Please refer to this amazing book for details.</em></p>
<p>&hellip;</p>
<p>So, what is a Markov chain? Lets break this term into two pieces: <em>Markov</em> and <em>chain</em>. It&rsquo;s a chain satisfying Markov property.</p>
<h3 id="what-is-a-chain">What is a chain?</h3>
<p>A chain, in this context, is a sequence of random variables $X_0, X_1, &hellip;, X_n$ taking values in the state space $\{1, 2, &hellip;, M\}$. We can understand $X_n$ as states of a system evolving through time (the index $0, 1, &hellip;, n$ is indicative of time).</p>
<p>For example, let $X_n$ be the random variable denoting the weather (either <em>sunny</em> (S), or <em>rainy</em> (R)) of the $n^{th}$ day from a specific day. Then, a chain of weathers is something like this: <em>S â†’ S â†’ R â†’ S â†’ R â†’ S</em>.</p>
<p>Another example: An English sentence is a sequence of characters. For simplicity, let&rsquo;s consider sentences containing only lowercased characters in the English alphabet and spacing character. We can model a sentence using a chain of random variables with the state space is $\{a, b, &hellip;, z, \txt{&quot; &ldquo;}\}$. The intuition of <em>time</em> in this example is the order in which a character appears (ie. the index of that character). For instance, the text &ldquo;hello&rdquo; is a chain where $X_1 = &ldquo;h&rdquo;, X_2 = &ldquo;e&rdquo;, X_3 = &ldquo;l&rdquo;, X_4 = &ldquo;l&rdquo;, X_5 = &ldquo;o&rdquo;$.</p>
<h3 id="markov-property">Markov property</h3>
<p><em><strong>Markov property</strong></em> states that given the entire past history $X_0, X_1, &hellip;, X_n$ , the prediction of $X_{n+1}$ only depends on the latest term (aka. $X_n$).</p>
<p>$$P(X_{n+1} = j | X_n = i, \dim{X_{n-1} = i_{n-1}, &hellip;, X_0 = i_0}) = P(X_{n+1} = j | X_n = i)$$</p>
<p>Consider $X_n$ as the present, $X_{n+1}$ as the future, and $X_{n-1}, &hellip;, X_0$ as the past, we have some interpretations:</p>
<ul>
<li><em>The future depends solely on the present, no matter how we got here</em></li>
<li><em>It is the present, not the past that affects the future</em> (sound philosophical ðŸ˜‚)</li>
<li><em>The outdated information in the past does not have influence on the future outcomes</em></li>
</ul>
<p>The English sentence example above does not practically satisfy Markov property. Let&rsquo;s just ask this question: <em>what is the likelihood that a space character follows letter &ldquo;t&rdquo;?</em>. Intuitively, we know that there&rsquo;s fairly possible that it happens (if &ldquo;t&rdquo; is at the end of the word, for instance). But when &ldquo;t&rdquo; is preceded a space character, there is much less likely that it is followed by a space character.</p>
<p>Similarly, the weather chain mentioned earlier may not fit well this property. Domain knowledge could show that the weather of a certain day can be influenced by 2 consecutive days ahead. However, we could adjust the chain to satisfy this property by expanding the state space that one describes the 2-consecutive-day weathers: $\{SS, SR, RS, RR\}$.</p>
<h3 id="describe-a-markov-chain">Describe a Markov chain</h3>
<p>We describe a Markov chain by its <em>state space</em> and <em>how likely is it to move from one state to another</em>.</p>
<h4 id="transition-matrix">Transition matrix</h4>
<p>Let $q_{ij} = P(X_{n+1} = j | X_n = i)$
be the <em><strong>transition probability</strong></em> of going from state $i$ to state $j$. The $M \times M$ matrix $Q = (q_{ij})$ is called the <em><strong>transition matrix</strong></em> of the chain.</p>
<p>For example, if today is sunny, there is 70% chance that tomorrow is sunny. Otherwise, if today is rainy, there is 50% chance that tomorrow is rainy. Then the transition matrix is given as follows:</p>
<p>$$
Q = \begin{pmatrix}
0.7 &amp; 0.3 \\ 0.5 &amp; 0.5
\end{pmatrix}
$$</p>
<p>Note that each row in a transition matrix always sums to 1.</p>
<p>This Markov chain can be visualized as this graph:</p>
<p><img src="/images/misc/markov_1.png" alt="png"></p>
<h4 id="n-step-transition-probability"><em>n</em>-step transition probability</h4>
<p><em><strong>n-step transition probability</strong></em> is the probability of reaching a state from another state after exactly $n$ steps. We denote it by:
$q_{ij}^{(n)} = P(X_{n}=j | X_0=i)$.</p>
<p>Now, consider the 2-step transition probability of a Markov chain. By marginal distribution, we have:</p>
<p>$$
\begin{aligned}
q_{ij}^{(2)} &amp;= P(X_{2} = j | X_0 = i) \\ &amp;= \sum_{k=1}^M P(X_{2} = j | X_{1} = k, X_0 = i) P(X_{1} = k | X_0 = i) \\ &amp;= \sum_{k=1}^M q_{kj} q_{ik} = \txt{the} (i, j) \txt{entry of} Q^2
\end{aligned}
$$</p>
<p>Similarly reasoning shows that $q_{ij}^{(n)}$ is the $(i, j)$ entry of $Q^n$.</p>
<p>With the weather example above, the matrix representing the 2-step transition probability is given by</p>
<p>$$
Q^2 = \begin{pmatrix}
0.64 &amp; 0.36 \\ 0.6 &amp; 0.4
\end{pmatrix}
$$</p>
<p>which implies given that today is sunny, there is 36% chance it will rain two days later.</p>
<p>Note that, in this example, we assume that the transition probability does not change along with time. Such Markov chain is called <em><strong>homogeneous</strong></em> or <em>time-homogeneous</em>.</p>
<h4 id="marginal-distribution-of-x_n">Marginal distribution of $X_n$</h4>
<p>One may ask <em>&ldquo;What is the probability the system arrives at a specific state at certain time?&quot;</em>. Or what is $P(X_n = j)$?</p>
<p>To calculate this marginal distribution, we need to know the <em>initial conditions</em> of the system. Let $\mathbf{t} = (t_1, &hellip;, t_M)$ be the probability vector where $t_i = P(X_0 = i)$, denoting the probability that the system starts at state $i$. Then,</p>
<p>$$
\begin{aligned}
P(X_{n} = j) &amp;= \sum_{i=1}^M P(X_0 = i) P(X_{n} = j | X_{0} = i) \\ &amp;= \sum_{i=1}^M  t_i q_{ij}^{(n)} = \txt{the }i^{th} \txt{entry of} \mathbf{t}Q^n
\end{aligned}
$$</p>
<p>So, the marginal distribution of $X_n$ is encoded by $\mathbf{t}Q^n$.</p>
<p>&hellip;</p>
<p>Now, you may wonder what $P(X_n = j)$ looks like in the long run. Does it have any special behavior? We will look at it in the next part of the series.</p>

  <div class="entry-footer">
  
<div class="categories">
  <svg class='icon' viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
  
  <path d="M22,19a2,2,0,0,1-2,2H4a2,2,0,0,1-2-2V5A2,2,0,0,1,4,3H9l2,3h9a2,2,0,0,1,2,2Z"/>
  
</svg>

  
  <a href="/categories/tech" class="category">tech</a>
  
</div>

  
<div class="tags">
  <svg class='icon' viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
  
  <path d="M20.59,13.41l-7.17,7.17a2,2,0,0,1-2.83,0L2,12V2H12l8.59,8.59A2,2,0,0,1,20.59,13.41Z"/>
  <line x1="7" y1="7" x2="7" y2="7"/>
  
</svg>

  
  <a href="/tags/probability" class="tag">probability</a>
  
  <a href="/tags/statistics" class="tag">statistics</a>
  
  <a href="/tags/markov-chain" class="tag">markov-chain</a>
  
</div>

</div>
</article>


<nav class='entry-nav'><div class='prev-entry'>
    <a href='/posts/tech/indicator-rvs-and-the-fundamental-bridge/'>Indicator r.v.s and the fundamental bridge</a>
  </div><div class='next-entry'>
    <a href='/posts/tech/config-run-shell-script-on-login/'>Config: Run shell script on login</a>
  </div></nav>


<section id='comments' class='comments'>
  
  
  <div class="container">
    <div id="fb-root"></div>
<script async defer crossorigin="anonymous" src="https://connect.facebook.net/en_US/sdk.js#xfbml=1&version=v5.0"></script>
<div class="share">
  <div class="fb-like" data-href="https://trinhngocthuyen.github.io/posts/tech/markov-chain-part-1/" data-width="" data-layout="standard" data-action="like" data-share="true"></div>
</div>

  </div>
  
  
  <div class="container">
    
  </div>
</section>


</main><script type='text/x-mathjax-config'>
  MathJax.Hub.Config({"HTML-CSS":{"availableFonts":["TeX"],"linebreaks":{"automatic":true},"scale":90},"TeX":{"Macros":{"dim":["{\\color{gray}#1}",1],"txt":["\\hspace{3pt}\\text{#1}\\hspace{3pt}",1]},"TagSide":"left","extensions":["color.js"]},"extensions":["tex2jax.js","TeX/AMSmath.js","TeX/AMSsymbols.js"],"jax":["input/TeX","output/HTML-CSS"],"tex2jax":{"displayMath":[["$$","$$"]],"inlineMath":[["$","$"]],"processEnvironments":true,"processEscapes":true}})
</script>

<script type='text/javascript' async src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_HTML'></script></body>
</html>